{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":126118,"databundleVersionId":14933142,"sourceType":"competition"}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install rasterio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:12.824222Z","iopub.execute_input":"2026-02-13T15:31:12.824528Z","iopub.status.idle":"2026-02-13T15:31:19.260444Z","shell.execute_reply.started":"2026-02-13T15:31:12.824496Z","shell.execute_reply":"2026-02-13T15:31:19.259472Z"}},"outputs":[{"name":"stdout","text":"Collecting rasterio\n  Downloading rasterio-1.5.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (8.6 kB)\nCollecting affine (from rasterio)\n  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\nRequirement already satisfied: attrs in /usr/local/lib/python3.12/dist-packages (from rasterio) (25.4.0)\nRequirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from rasterio) (2026.1.4)\nRequirement already satisfied: click!=8.2.*,>=4.0 in /usr/local/lib/python3.12/dist-packages (from rasterio) (8.3.1)\nRequirement already satisfied: cligj>=0.5 in /usr/local/lib/python3.12/dist-packages (from rasterio) (0.7.2)\nRequirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from rasterio) (2.0.2)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from rasterio) (3.2.5)\nDownloading rasterio-1.5.0-cp312-cp312-manylinux_2_28_x86_64.whl (37.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading affine-2.4.0-py3-none-any.whl (15 kB)\nInstalling collected packages: affine, rasterio\nSuccessfully installed affine-2.4.0 rasterio-1.5.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:19.262697Z","iopub.execute_input":"2026-02-13T15:31:19.263114Z","iopub.status.idle":"2026-02-13T15:31:22.688253Z","shell.execute_reply.started":"2026-02-13T15:31:19.263071Z","shell.execute_reply":"2026-02-13T15:31:22.687449Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.3)\nRequirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.36.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (26.0rc2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2025.11.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.5)\nRequirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.10.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.2.1rc0)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.4)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.11)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.6.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2026.1.4)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom torch.nn.parallel import DataParallel\nimport numpy as np\nimport cv2\nimport rasterio\nfrom pathlib import Path\nimport copy\nimport random\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm.auto import tqdm\nimport pandas as pd\n\ndevice    = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_gpus    = torch.cuda.device_count()\nDATA_ROOT = \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026p2/ICPR02/kaggle\"\nSSL_ROOT  = \"/kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026p2/archive/share\"\n\nprint(f\"Device: {device} | GPUs: {n_gpus}\")\nprint(f\"Data root: {DATA_ROOT}\")\nprint(f\"SSL root:  {SSL_ROOT}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:22.692246Z","iopub.execute_input":"2026-02-13T15:31:22.692506Z","iopub.status.idle":"2026-02-13T15:31:29.287946Z","shell.execute_reply.started":"2026-02-13T15:31:22.692479Z","shell.execute_reply":"2026-02-13T15:31:29.287344Z"}},"outputs":[{"name":"stdout","text":"Device: cuda | GPUs: 2\nData root: /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026p2/ICPR02/kaggle\nSSL root:  /kaggle/input/beyond-visible-spectrum-ai-for-agriculture-2026p2/archive/share\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:29.288823Z","iopub.execute_input":"2026-02-13T15:31:29.289213Z","iopub.status.idle":"2026-02-13T15:31:29.294575Z","shell.execute_reply.started":"2026-02-13T15:31:29.289188Z","shell.execute_reply":"2026-02-13T15:31:29.294002Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"# Temporal Dataset","metadata":{}},{"cell_type":"code","source":"class TemporalSSLDataset(Dataset):\n    \"\"\"\n    For each field, samples two date acquisitions as a positive pair.\n    If a field only has one date, pairs with itself using augmentation.\n    Includes both train (crop/field/date) and val (field/bands) structures.\n    \"\"\"\n    def __init__(self, ssl_root, target_size=(224, 224)):\n        self.target_size = target_size\n        self.bands = [\n            'B1','B2','B3','B4','B5','B6',\n            'B7','B8','B8A','B9','B11','B12'\n        ]\n\n        # field_id → list of paths that contain B1.tif\n        self.fields = {}\n\n        ssl_root = Path(ssl_root)\n\n        # train: share/train/{crop}/{field_id}/{date_folder}/B1.tif\n        train_dir = ssl_root / \"train\"\n        if train_dir.exists():\n            for crop_dir in sorted(train_dir.iterdir()):\n                if not crop_dir.is_dir():\n                    continue\n                for field_dir in sorted(crop_dir.iterdir()):\n                    if not field_dir.is_dir():\n                        continue\n                    key = f\"{crop_dir.name}_{field_dir.name}\"\n                    dates = []\n                    for date_dir in sorted(field_dir.iterdir()):\n                        if date_dir.is_dir() and (date_dir / \"B1.tif\").exists():\n                            dates.append(date_dir)\n                    if dates:\n                        self.fields[key] = dates\n\n        # val: share/val/{field_id}/B1.tif\n        val_dir = ssl_root / \"val\"\n        if val_dir.exists():\n            for field_dir in sorted(val_dir.iterdir()):\n                if field_dir.is_dir() and (field_dir / \"B1.tif\").exists():\n                    key = f\"val_{field_dir.name}\"\n                    self.fields[key] = [field_dir]\n\n        self.field_keys = list(self.fields.keys())\n        print(f\"SSL dataset: {len(self.field_keys)} fields, \"\n              f\"{sum(len(v) for v in self.fields.values())} total acquisitions\")\n        multi = sum(1 for v in self.fields.values() if len(v) >= 2)\n        print(f\"  Fields with 2+ dates (temporal pairs): {multi}\")\n        print(f\"  Fields with 1 date  (self-pairs):      {len(self.field_keys)-multi}\")\n\n    def __len__(self):\n        return len(self.field_keys)\n\n    def _load(self, path):\n        bands = []\n        for b in self.bands:\n            with rasterio.open(path / f\"{b}.tif\") as src:\n                x = src.read(1).astype(np.float32)\n                if x.shape != self.target_size:\n                    x = cv2.resize(x, self.target_size)\n                bands.append(x)\n        return torch.from_numpy(np.stack(bands))   # (12, H, W)\n\n    def _augment(self, x):\n        \"\"\"Light augmentation used for self-pairs only\"\"\"\n        _, H, W = x.shape\n        crop = torch.randint(int(0.7*H), H+1, (1,)).item()\n        i    = torch.randint(0, H-crop+1, (1,)).item()\n        j    = torch.randint(0, W-crop+1, (1,)).item()\n        x    = x[:, i:i+crop, j:j+crop]\n        x    = F.interpolate(x.unsqueeze(0), size=self.target_size,\n                             mode='bilinear', align_corners=False).squeeze(0)\n        if torch.rand(1) > 0.5:\n            x = torch.flip(x, [2])\n        x = x + 0.01 * torch.randn_like(x)\n        return x\n\n    def __getitem__(self, idx):\n        key   = self.field_keys[idx]\n        dates = self.fields[key]\n\n        if len(dates) >= 2:\n            # real temporal pair — sample two different dates\n            d1, d2 = random.sample(dates, 2)\n            view1  = self._load(d1)\n            view2  = self._load(d2)\n        else:\n            # self-pair with augmentation\n            view1 = self._load(dates[0])\n            view2 = self._augment(self._load(dates[0]))\n\n        return view1, view2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:29.295520Z","iopub.execute_input":"2026-02-13T15:31:29.295763Z","iopub.status.idle":"2026-02-13T15:31:29.312167Z","shell.execute_reply.started":"2026-02-13T15:31:29.295742Z","shell.execute_reply":"2026-02-13T15:31:29.311456Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Disease Dataset Class","metadata":{}},{"cell_type":"code","source":"class S2Disease(Dataset):\n    def __init__(self, root_dir, is_eval=False, target_size=(224, 224)):\n        self.root_dir    = Path(root_dir)\n        self.is_eval     = is_eval\n        self.target_size = target_size\n        self.bands = [\n            'B1','B2','B3','B4','B5','B6',\n            'B7','B8','B8A','B9','B11','B12'\n        ]\n\n        if is_eval:\n            self.samples      = list((self.root_dir / \"evaluation\").glob(\"*/\"))\n            self.classes      = ['Aphid', 'Blast', 'RPH', 'Rust']\n            self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n        else:\n            all_dirs          = [d for d in self.root_dir.iterdir() if d.is_dir()]\n            self.classes      = sorted([d.name for d in all_dirs if d.name != \"evaluation\"])\n            self.class_to_idx = {n: i for i, n in enumerate(self.classes)}\n            self.samples      = []\n            for cls in self.classes:\n                self.samples.extend(list((self.root_dir / cls).glob(\"*/\")))\n\n        self.idx_to_class = {v: k for k, v in self.class_to_idx.items()}\n        self.num_classes  = len(self.classes)\n\n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        sample_path = self.samples[idx]\n        band_data   = []\n        for band in self.bands:\n            with rasterio.open(sample_path / f\"{band}.tif\") as src:\n                data = src.read(1).astype(np.float32)\n                if data.shape != self.target_size:\n                    data = cv2.resize(data, self.target_size,\n                                      interpolation=cv2.INTER_LINEAR)\n                band_data.append(data)\n\n        image = torch.from_numpy(np.stack(band_data))\n\n        if self.is_eval:\n            label = torch.zeros(self.num_classes)\n        else:\n            cls_name        = sample_path.parent.name\n            label           = torch.zeros(self.num_classes)\n            label[self.class_to_idx[cls_name]] = 1.0\n\n        return {\n            'image':     image,\n            'label':     label,\n            'sample_id': sample_path.name\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:29.313841Z","iopub.execute_input":"2026-02-13T15:31:29.314064Z","iopub.status.idle":"2026-02-13T15:31:29.328264Z","shell.execute_reply.started":"2026-02-13T15:31:29.314043Z","shell.execute_reply":"2026-02-13T15:31:29.327632Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# Spectral Band","metadata":{}},{"cell_type":"code","source":"class SpectralMixer(nn.Module):\n    \"\"\"\n    1x1 conv: learns cross-band relationships before patch embedding.\n    Projects 12 bands → 64 learned spectral features.\n    \"\"\"\n    def __init__(self, in_bands=12, out_channels=64):\n        super().__init__()\n        self.conv = nn.Conv2d(in_bands, out_channels, kernel_size=1, bias=False)\n        self.bn   = nn.BatchNorm2d(out_channels)\n        self.act  = nn.GELU()\n\n    def forward(self, x):\n        return self.act(self.bn(self.conv(x)))\n\n\nclass PatchEmbed(nn.Module):\n    \"\"\"Standard ViT patch embedding on mixed spectral features\"\"\"\n    def __init__(self, in_channels=64, patch_size=16, img_size=224, embed_dim=384):\n        super().__init__()\n        self.patch_size = patch_size\n        self.n_patches  = (img_size // patch_size) ** 2\n        self.proj       = nn.Conv2d(in_channels, embed_dim,\n                                    kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):\n        # x: (B, C, H, W) → (B, n_patches, embed_dim)\n        x = self.proj(x)                    # (B, embed_dim, H/p, W/p)\n        x = x.flatten(2).transpose(1, 2)   # (B, n_patches, embed_dim)\n        return x\n\n\ndef compute_spectral_variance(x, patch_size=16):\n    \"\"\"\n    Computes band variance per patch from raw 12-band input.\n    Used to identify low-information patches (uniform soil, water).\n\n    Args:\n        x: (B, 12, H, W) raw bands\n    Returns:\n        variance: (B, n_patches) per-patch spectral variance\n    \"\"\"\n    B, C, H, W = x.shape\n    n_ph = H // patch_size\n    n_pw = W // patch_size\n\n    # reshape into patches: (B, C, n_ph, patch_size, n_pw, patch_size)\n    x_p = x.reshape(B, C, n_ph, patch_size, n_pw, patch_size)\n    # (B, n_ph, n_pw, C, patch_size, patch_size)\n    x_p = x_p.permute(0, 2, 4, 1, 3, 5)\n    # (B, n_patches, C * patch_size * patch_size)\n    x_p = x_p.reshape(B, n_ph * n_pw, -1)\n\n    # variance across spectral+spatial dimensions per patch\n    var = x_p.var(dim=-1)   # (B, n_patches)\n    return var\n\n\nclass SpectraMaskViT(nn.Module):\n    \"\"\"\n    Full architecture:\n      1. SpectralMixer:   12 bands → 64 learned spectral features\n      2. PatchEmbed:      64 → 384-dim tokens (16x16 patches → 196 tokens)\n      3. EntropyMask:     remove bottom 30% lowest-variance patches\n      4. ViT-Small:       6 layers, 384 dim, 6 heads\n      5. Head:            DINO projection (SSL) or MLP (fine-tuning)\n    \"\"\"\n    def __init__(self, img_size=224, patch_size=16,\n                 embed_dim=384, depth=6, n_heads=6,\n                 mlp_ratio=4.0, mask_ratio=0.30):\n        super().__init__()\n\n        self.patch_size  = patch_size\n        self.mask_ratio  = mask_ratio\n        self.embed_dim   = embed_dim\n        self.n_patches   = (img_size // patch_size) ** 2   # 196\n\n        # spectral mixing layer\n        self.spectral_mixer = SpectralMixer(in_bands=12, out_channels=64)\n\n        # patch embedding\n        self.patch_embed = PatchEmbed(\n            in_channels=64, patch_size=patch_size,\n            img_size=img_size, embed_dim=embed_dim\n        )\n\n        # learnable CLS token and position embedding\n        self.cls_token = nn.Parameter(torch.zeros(1, 1, embed_dim))\n        self.pos_embed = nn.Parameter(torch.zeros(1, self.n_patches + 1, embed_dim))\n        nn.init.trunc_normal_(self.cls_token, std=0.02)\n        nn.init.trunc_normal_(self.pos_embed, std=0.02)\n\n        # ViT-Small transformer blocks\n        self.blocks = nn.ModuleList([\n            nn.TransformerEncoderLayer(\n                d_model    = embed_dim,\n                nhead      = n_heads,\n                dim_feedforward = int(embed_dim * mlp_ratio),\n                dropout    = 0.0,\n                activation = 'gelu',\n                batch_first = True,\n                norm_first  = True    # pre-norm (more stable)\n            )\n            for _ in range(depth)\n        ])\n\n        self.norm     = nn.LayerNorm(embed_dim)\n        self.num_features = embed_dim   # used by DINOHead\n\n    def forward(self, x):\n        B = x.shape[0]\n\n        # 1. compute spectral variance BEFORE mixing (from raw bands)\n        var = compute_spectral_variance(x, self.patch_size)   # (B, 196)\n\n        # 2. spectral mixing\n        x = self.spectral_mixer(x)   # (B, 64, H, W)\n\n        # 3. patch embedding\n        x = self.patch_embed(x)      # (B, 196, 384)\n\n        # 4. entropy masking — remove bottom mask_ratio% patches by variance\n        n_keep   = int(self.n_patches * (1 - self.mask_ratio))   # keep top 70%\n        # get indices of top-n_keep patches by variance\n        _, keep_idx = torch.topk(var, n_keep, dim=1)              # (B, n_keep)\n        keep_idx    = keep_idx.sort(dim=1).values                 # keep order\n        # gather kept patches\n        keep_idx_exp = keep_idx.unsqueeze(-1).expand(-1, -1, self.embed_dim)\n        x            = torch.gather(x, 1, keep_idx_exp)          # (B, n_keep, 384)\n\n        # 5. prepend CLS token and add position embeddings\n        cls    = self.cls_token.expand(B, -1, -1)                 # (B, 1, 384)\n        x      = torch.cat([cls, x], dim=1)                       # (B, n_keep+1, 384)\n\n        # position embed: CLS gets pos 0, kept patches get their original positions\n        cls_pos  = self.pos_embed[:, :1]                          # (1, 1, 384)\n        patch_pos = self.pos_embed[:, 1:].expand(B, -1, -1)      # (B, 196, 384)\n        kept_pos  = torch.gather(\n            patch_pos, 1,\n            keep_idx.unsqueeze(-1).expand(-1, -1, self.embed_dim)\n        )                                                          # (B, n_keep, 384)\n        pos = torch.cat([cls_pos.expand(B, -1, -1), kept_pos], dim=1)\n        x   = x + pos\n\n        # 6. transformer blocks\n        for block in self.blocks:\n            x = block(x)\n\n        x = self.norm(x)\n\n        # return CLS token as representation\n        return x[:, 0]   # (B, 384)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:29.329085Z","iopub.execute_input":"2026-02-13T15:31:29.329321Z","iopub.status.idle":"2026-02-13T15:31:29.345509Z","shell.execute_reply.started":"2026-02-13T15:31:29.329297Z","shell.execute_reply":"2026-02-13T15:31:29.344873Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# DINO Encoder","metadata":{}},{"cell_type":"code","source":"class DINOHead(nn.Module):\n    def __init__(self, in_dim, out_dim=65536):\n        super().__init__()\n        self.mlp = nn.Sequential(\n            nn.Linear(in_dim, 2048),\n            nn.GELU(),\n            nn.Linear(2048, out_dim)\n        )\n    def forward(self, x):\n        return self.mlp(x)\n\n\nclass DINOLoss(nn.Module):\n    def __init__(self, out_dim, temp_s=0.1, temp_t=0.04):\n        super().__init__()\n        self.temp_s = temp_s\n        self.temp_t = temp_t\n        self.register_buffer(\"center\", torch.zeros(1, out_dim))\n\n    def forward(self, student, teacher):\n        t    = F.softmax((teacher - self.center) / self.temp_t, dim=-1)\n        s    = student / self.temp_s\n        loss = torch.sum(-t * F.log_softmax(s, dim=-1), dim=-1).mean()\n        self.center = 0.9 * self.center + 0.1 * teacher.mean(dim=0, keepdim=True)\n        return loss\n\n\n@torch.no_grad()\ndef update_teacher(student, teacher, m=0.996):\n    for ps, pt in zip(student.parameters(), teacher.parameters()):\n        pt.data = m * pt.data + (1 - m) * ps.data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:44.585425Z","iopub.execute_input":"2026-02-13T15:31:44.585735Z","iopub.status.idle":"2026-02-13T15:31:44.593305Z","shell.execute_reply.started":"2026-02-13T15:31:44.585708Z","shell.execute_reply":"2026-02-13T15:31:44.592573Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# SSL Model Initialization","metadata":{}},{"cell_type":"code","source":"ssl_dataset = TemporalSSLDataset(ssl_root=SSL_ROOT, target_size=(224, 224))\nssl_loader  = DataLoader(\n    ssl_dataset,\n    batch_size = 32 * max(n_gpus, 1),   # scale batch with GPU count\n    shuffle    = True,\n    num_workers = 0\n)\n\nprint(f\"SSL batches per epoch: {len(ssl_loader)}\")\n\n# build student and teacher\nencoder_s = SpectraMaskViT().to(device)\nencoder_t = copy.deepcopy(encoder_s).to(device)\nfor p in encoder_t.parameters():\n    p.requires_grad = False\n\nhead_s = DINOHead(encoder_s.num_features).to(device)\nhead_t = DINOHead(encoder_t.num_features).to(device)\n\n# DataParallel for dual T4\nif n_gpus > 1:\n    encoder_s = DataParallel(encoder_s)\n    encoder_t = DataParallel(encoder_t)\n    head_s    = DataParallel(head_s)\n    head_t    = DataParallel(head_t)\n    print(f\"✓ DataParallel enabled across {n_gpus} GPUs\")\n\ncriterion_ssl = DINOLoss(out_dim=65536).to(device)\noptimizer_ssl = torch.optim.AdamW(\n    list(encoder_s.parameters()) + list(head_s.parameters()),\n    lr=1e-4, weight_decay=0.05\n)\nscaler = torch.amp.GradScaler('cuda')\n\nprint(\"✓ SSL models ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:31:46.272721Z","iopub.execute_input":"2026-02-13T15:31:46.273471Z","iopub.status.idle":"2026-02-13T15:32:16.847897Z","shell.execute_reply.started":"2026-02-13T15:31:46.273431Z","shell.execute_reply":"2026-02-13T15:32:16.847125Z"}},"outputs":[{"name":"stdout","text":"SSL dataset: 1164 fields, 2960 total acquisitions\n  Fields with 2+ dates (temporal pairs): 722\n  Fields with 1 date  (self-pairs):      442\nSSL batches per epoch: 19\n✓ DataParallel enabled across 2 GPUs\n✓ SSL models ready\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Encoder Training Loop","metadata":{}},{"cell_type":"code","source":"SSL_EPOCHS = 50\n\nprint(f\"Starting SSL pretraining for {SSL_EPOCHS} epochs...\")\n\nfor ep in range(SSL_EPOCHS):\n    encoder_s.train()\n    total_loss = 0\n\n    for view1, view2 in tqdm(ssl_loader, desc=f\"SSL {ep+1}/{SSL_EPOCHS}\", leave=True):\n        view1, view2 = view1.to(device), view2.to(device)\n\n        optimizer_ssl.zero_grad()\n\n        with torch.amp.autocast('cuda'):\n            # student sees both views\n            f1    = encoder_s(view1)\n            f2    = encoder_s(view2)\n            s_out = head_s((f1 + f2) / 2)\n\n            # teacher sees both views (no grad)\n            with torch.no_grad():\n                t1    = encoder_t(view1)\n                t2    = encoder_t(view2)\n                t_out = head_t((t1 + t2) / 2).detach()\n\n            loss = criterion_ssl(s_out, t_out)\n\n        scaler.scale(loss).backward()\n        scaler.step(optimizer_ssl)\n        scaler.update()\n\n        # EMA teacher update\n        update_teacher(encoder_s, encoder_t)\n        update_teacher(head_s,    head_t)\n\n        total_loss += loss.item()\n\n    print(f\"SSL Epoch {ep+1}/{SSL_EPOCHS} | Loss: {total_loss/len(ssl_loader):.4f}\")\n\n# unwrap DataParallel before saving\nencoder_to_save = encoder_s.module if isinstance(encoder_s, DataParallel) else encoder_s\ntorch.save(encoder_to_save.state_dict(), 'ssl_encoder.pth')\nprint(\"✓ SSL pretraining complete — saved to ssl_encoder.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T15:33:02.472056Z","iopub.execute_input":"2026-02-13T15:33:02.472745Z","iopub.status.idle":"2026-02-13T16:52:09.663665Z","shell.execute_reply.started":"2026-02-13T15:33:02.472713Z","shell.execute_reply":"2026-02-13T16:52:09.662877Z"}},"outputs":[{"name":"stdout","text":"Starting SSL pretraining for 50 epochs...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 1/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"694a68f64d5c484495885326a4e4d252"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.12/dist-packages/rasterio/__init__.py:367: NotGeoreferencedWarning: Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.\n  dataset = DatasetReader(path, driver=driver, sharing=sharing, thread_safe=thread_safe, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"SSL Epoch 1/50 | Loss: 9.9786\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 2/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58fcd6e1bc8440b89ada4441f43ccac3"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 2/50 | Loss: 9.2339\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 3/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f137e3f16dd4f03918aa6505082e0d4"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 3/50 | Loss: 9.1277\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 4/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10f39ed3c8b543de9f2e9f32849840b2"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 4/50 | Loss: 9.2203\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 5/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1095ec355724399ae755a88f2813546"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 5/50 | Loss: 9.2727\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 6/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"411628f9a6314eca901497f369c0df14"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 6/50 | Loss: 9.2725\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 7/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64c02a8b391c4efebcdaaaf2b41c19f5"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 7/50 | Loss: 9.1786\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 8/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f52ef4225fa84b18abb437c90b9fd5a0"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 8/50 | Loss: 9.0392\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 9/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6e9978469d7940cdb8b354a172166d59"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 9/50 | Loss: 8.8624\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 10/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a372b785404745e9af5aa7b9b5a36a16"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 10/50 | Loss: 8.5780\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 11/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c296e0ae86a493988546b892242e654"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 11/50 | Loss: 8.2909\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 12/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0f5be129c1f42a29ef2d2da663bae1e"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 12/50 | Loss: 7.9639\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 13/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f12682e7b43d4ece9f039751f3ad892e"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 13/50 | Loss: 7.4618\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 14/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3156bd628304df2a46971823c1d3f7d"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 14/50 | Loss: 7.0945\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 15/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22558d28a6bd477eaa57df0ea58723b8"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 15/50 | Loss: 6.6955\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 16/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"50f42e0825294e9fb4645e004701dea8"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 16/50 | Loss: 6.3046\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 17/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b647135daf8e4a919a37c3facf390056"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 17/50 | Loss: 5.9631\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 18/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bfc3df140b1e430bbc5d6892e3136485"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 18/50 | Loss: 5.4132\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 19/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5088a668a4fa4fe4b9aae1aa046dc65e"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 19/50 | Loss: 5.0578\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 20/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0782b0a1164f269a60dea404dce988"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 20/50 | Loss: 4.6652\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 21/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f3b581899c9d46b0a854e6808b888ca9"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 21/50 | Loss: 4.2335\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 22/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5705dde5af044c0b4d816498768f52f"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 22/50 | Loss: 3.8254\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 23/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ce62009dafa4f079a17f6836df85f03"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 23/50 | Loss: 3.5820\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 24/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"374a5dbc2c2542af8ed8755bf2d13f36"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 24/50 | Loss: 3.2230\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 25/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"308d2c12d4384bdf9d5ff8baa730a6e9"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 25/50 | Loss: 2.9232\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 26/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8b53d49a1d824d60a4567c40e6496141"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 26/50 | Loss: 2.6489\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 27/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93e89f1de53842fba7a2d4363c810c49"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 27/50 | Loss: 2.2735\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 28/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3b7bbb22ca9045c985d450bad6ddecf2"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 28/50 | Loss: 2.0453\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 29/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a1badedbaee4d7ba719393814c399c3"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 29/50 | Loss: 1.9663\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 30/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6c908ddfc7e0405c91f9827cd59df37f"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 30/50 | Loss: 1.6947\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 31/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7dde4891d32c4ef9a9e10d9ec5e33fb3"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 31/50 | Loss: 1.4331\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 32/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e25f3721a5624fc68598db0bded684e4"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 32/50 | Loss: 1.2997\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 33/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff4a293a8e0c425fb9c1b26145f5e735"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 33/50 | Loss: 1.3064\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 34/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bd2a55420f3e4aa3a721ea8829a75688"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 34/50 | Loss: 1.2739\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 35/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94ddecd0281f4a948ebc4b0000a15a88"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 35/50 | Loss: 1.3166\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 36/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2c1ebb0d95d84003a4c42ae52368a4be"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 36/50 | Loss: 1.0306\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 37/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"68e03b7507a24d4c87e6817bb31e222c"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 37/50 | Loss: 1.0104\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 38/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6b3050f271843c9960a645c63ecf5d3"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 38/50 | Loss: 1.0303\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 39/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"831249393ddc4c2ab723287bbf670103"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 39/50 | Loss: 0.9295\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 40/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"557c34c792574941b69e583405e16bba"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 40/50 | Loss: 0.7220\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 41/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e0e73475c694d17b26dd1838246225e"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 41/50 | Loss: 0.8439\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 42/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"93271de4ccca4793bad368a2365cb22f"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 42/50 | Loss: 0.7251\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 43/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be33e16d26b34054a88a136dd1a64e0d"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 43/50 | Loss: 0.6592\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 44/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4906fed98b024e878ff2cf158ff20694"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 44/50 | Loss: 0.6179\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 45/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4633ff089b4249239bc76a9bca04feb7"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 45/50 | Loss: 0.5843\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 46/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a79c3ed864b64bca9181fef7644aca3a"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 46/50 | Loss: 0.6063\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 47/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c49380915c4941b493ed6c2b618d9c0f"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 47/50 | Loss: 0.7526\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 48/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ceb4574912f4a47b2e49343deb68b57"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 48/50 | Loss: 0.6623\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 49/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03a89779b2544eac83fdcace4d25edd7"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 49/50 | Loss: 0.5696\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"SSL 50/50:   0%|          | 0/19 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"94b793f2271646e89fac2daca786c761"}},"metadata":{}},{"name":"stdout","text":"SSL Epoch 50/50 | Loss: 0.5045\n✓ SSL pretraining complete — saved to ssl_encoder.pth\n","output_type":"stream"}],"execution_count":12},{"cell_type":"markdown","source":"# Classifier Head","metadata":{}},{"cell_type":"code","source":"class SpectraMaskViTClassifier(nn.Module):\n    \"\"\"\n    Pretrained SpectraMaskViT encoder + MLP classification head.\n    Unfreezes last N transformer blocks for fine-tuning.\n    \"\"\"\n    def __init__(self, encoder, num_classes, unfreeze_last_n=2):\n        super().__init__()\n        self.encoder = encoder\n\n        # freeze everything\n        for p in self.encoder.parameters():\n            p.requires_grad = False\n\n        # unfreeze spectral mixer — it needs to adapt to disease signals\n        for p in self.encoder.spectral_mixer.parameters():\n            p.requires_grad = True\n\n        # unfreeze last N transformer blocks\n        for block in self.encoder.blocks[-unfreeze_last_n:]:\n            for p in block.parameters():\n                p.requires_grad = True\n\n        # unfreeze final norm\n        for p in self.encoder.norm.parameters():\n            p.requires_grad = True\n\n        hidden = self.encoder.num_features   # 384\n\n        self.head = nn.Sequential(\n            nn.Linear(hidden, 512),\n            nn.BatchNorm1d(512),\n            nn.ReLU(),\n            nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256),\n            nn.ReLU(),\n            nn.Dropout(0.2),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x):\n        feats = self.encoder(x)\n        return self.head(feats)\n\n\n# load pretrained SSL encoder\nssl_encoder = SpectraMaskViT()\nssl_encoder.load_state_dict(torch.load('ssl_encoder.pth'))\nssl_encoder = ssl_encoder.to(device)\nprint(\"✓ SSL encoder loaded\")\n\n# build classifier\ntrain_dataset = S2Disease(root_dir=DATA_ROOT, is_eval=False, target_size=(224, 224))\n\nmodel = SpectraMaskViTClassifier(\n    encoder         = ssl_encoder,\n    num_classes     = train_dataset.num_classes,\n    unfreeze_last_n = 2\n).to(device)\n\ntrainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\ntotal     = sum(p.numel() for p in model.parameters())\nprint(f\"✓ Classifier ready | Trainable: {trainable:,} / {total:,}\")\nprint(f\"  Unfrozen: spectral_mixer + last 2 blocks + norm\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T16:52:09.665297Z","iopub.execute_input":"2026-02-13T16:52:09.665568Z","iopub.status.idle":"2026-02-13T16:52:11.066966Z","shell.execute_reply.started":"2026-02-13T16:52:09.665546Z","shell.execute_reply":"2026-02-13T16:52:11.066260Z"}},"outputs":[{"name":"stdout","text":"✓ SSL encoder loaded\n✓ Classifier ready | Trainable: 3,881,604 / 17,347,332\n  Unfrozen: spectral_mixer + last 2 blocks + norm\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"# Balanced Dataset (Train + Test) by Augmentation","metadata":{}},{"cell_type":"code","source":"def val_normalize(x):\n    mean = x.mean(dim=(1, 2), keepdim=True)\n    std  = x.std(dim=(1, 2), keepdim=True) + 1e-6\n    return (x - mean) / std\n\ndef augment_strong(x):\n    _, H, W = x.shape\n    crop = torch.randint(int(0.6*H), H+1, (1,)).item()\n    i    = torch.randint(0, H-crop+1, (1,)).item()\n    j    = torch.randint(0, W-crop+1, (1,)).item()\n    x    = x[:, i:i+crop, j:j+crop]\n    x    = F.interpolate(x.unsqueeze(0), size=(H, W),\n                         mode='bilinear', align_corners=False).squeeze(0)\n    if torch.rand(1) > 0.5: x = torch.flip(x, [2])\n    if torch.rand(1) > 0.5: x = torch.flip(x, [1])\n    k = torch.randint(0, 4, (1,)).item()\n    x = torch.rot90(x, k, [1, 2])\n    if torch.rand(1) > 0.6:\n        drop = torch.randperm(12)[:torch.randint(1, 3, (1,)).item()]\n        x    = x.clone(); x[drop] = 0.0\n    x = x + 0.02 * torch.randn_like(x)\n    return val_normalize(x)\n\ndef augment_light(x):\n    _, H, W = x.shape\n    crop = torch.randint(int(0.8*H), H+1, (1,)).item()\n    i    = torch.randint(0, H-crop+1, (1,)).item()\n    j    = torch.randint(0, W-crop+1, (1,)).item()\n    x    = x[:, i:i+crop, j:j+crop]\n    x    = F.interpolate(x.unsqueeze(0), size=(H, W),\n                         mode='bilinear', align_corners=False).squeeze(0)\n    if torch.rand(1) > 0.5: x = torch.flip(x, [2])\n    x = x + 0.01 * torch.randn_like(x)\n    return val_normalize(x)\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, samples, labels, aug_flags, num_classes, target_size=(224,224)):\n        self.samples     = samples\n        self.labels      = labels\n        self.aug_flags   = aug_flags\n        self.num_classes = num_classes\n        self.target_size = target_size\n        self.bands = ['B1','B2','B3','B4','B5','B6',\n                      'B7','B8','B8A','B9','B11','B12']\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        band_data = []\n        for b in self.bands:\n            with rasterio.open(self.samples[idx] / f\"{b}.tif\") as src:\n                d = src.read(1).astype(np.float32)\n                if d.shape != self.target_size:\n                    d = cv2.resize(d, self.target_size, interpolation=cv2.INTER_LINEAR)\n                band_data.append(d)\n        image = torch.from_numpy(np.stack(band_data))\n        image = augment_strong(image) if self.aug_flags[idx] else augment_light(image)\n        label = torch.zeros(self.num_classes)\n        label[self.labels[idx]] = 1.0\n        return {'image': image, 'label': label, 'sample_id': self.samples[idx].name}\n\n\nclass ValDataset(Dataset):\n    def __init__(self, samples, labels, num_classes, target_size=(224,224)):\n        self.samples     = samples\n        self.labels      = labels\n        self.num_classes = num_classes\n        self.target_size = target_size\n        self.bands = ['B1','B2','B3','B4','B5','B6',\n                      'B7','B8','B8A','B9','B11','B12']\n\n    def __len__(self): return len(self.samples)\n\n    def __getitem__(self, idx):\n        band_data = []\n        for b in self.bands:\n            with rasterio.open(self.samples[idx] / f\"{b}.tif\") as src:\n                d = src.read(1).astype(np.float32)\n                if d.shape != self.target_size:\n                    d = cv2.resize(d, self.target_size, interpolation=cv2.INTER_LINEAR)\n                band_data.append(d)\n        image = torch.from_numpy(np.stack(band_data))\n        image = val_normalize(image)\n        label = torch.zeros(self.num_classes)\n        label[self.labels[idx]] = 1.0\n        return {'image': image, 'label': label, 'sample_id': self.samples[idx].name}\n\n\n# stratified split on original samples\nlabels_orig    = [train_dataset.class_to_idx[s.parent.name] for s in train_dataset.samples]\nskf            = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\ntr_idx, va_idx = list(skf.split(train_dataset.samples, labels_orig))[0]\n\norig_train_samples = [train_dataset.samples[i] for i in tr_idx]\norig_train_labels  = [labels_orig[i] for i in tr_idx]\nval_samples        = [train_dataset.samples[i] for i in va_idx]\nval_labels         = [labels_orig[i] for i in va_idx]\n\n# oversample training split — all classes to max count\ntrain_counts  = {}\nfor cls in train_dataset.classes:\n    idx = train_dataset.class_to_idx[cls]\n    train_counts[cls] = orig_train_labels.count(idx)\n\nmax_count = max(train_counts.values())\nbal_samples, bal_labels, bal_flags = [], [], []\n\nfor cls in train_dataset.classes:\n    idx      = train_dataset.class_to_idx[cls]\n    cls_samp = [s for s, l in zip(orig_train_samples, orig_train_labels) if l == idx]\n    n        = len(cls_samp)\n    for s in cls_samp:\n        bal_samples.append(s); bal_labels.append(idx); bal_flags.append(False)\n    for i in range(max_count - n):\n        bal_samples.append(cls_samp[i % n]); bal_labels.append(idx); bal_flags.append(True)\n\nprint(\"Balanced training class counts:\")\nfor cls in train_dataset.classes:\n    idx = train_dataset.class_to_idx[cls]\n    print(f\"  {cls}: {bal_labels.count(idx)}\")\nprint(f\"Total train: {len(bal_samples)} | Val: {len(val_samples)}\")\n\ntrain_ds = TrainDataset(bal_samples, bal_labels, bal_flags,\n                        train_dataset.num_classes)\nval_ds   = ValDataset(val_samples, val_labels, train_dataset.num_classes)\n\ntrain_loader = DataLoader(train_ds, batch_size=16, shuffle=True,  num_workers=0)\nval_loader   = DataLoader(val_ds,   batch_size=32, shuffle=False, num_workers=0)\n\nprint(\"✓ Val set: original samples only, no augmentation\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T16:52:11.067847Z","iopub.execute_input":"2026-02-13T16:52:11.068048Z","iopub.status.idle":"2026-02-13T16:52:11.107756Z","shell.execute_reply.started":"2026-02-13T16:52:11.068028Z","shell.execute_reply":"2026-02-13T16:52:11.107052Z"}},"outputs":[{"name":"stdout","text":"Balanced training class counts:\n  Aphid: 396\n  Blast: 396\n  RPH: 396\n  Rust: 396\nTotal train: 1584 | Val: 180\n✓ Val set: original samples only, no augmentation\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=None, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n    def forward(self, inputs, targets):\n        ce  = F.cross_entropy(inputs, targets, reduction='none', weight=self.alpha)\n        pt  = torch.exp(-ce)\n        return ((1 - pt) ** self.gamma * ce).mean()\n\n\n# class weights (p=0.5)\ncounts  = {c: len(list((Path(DATA_ROOT)/c).glob(\"*/\"))) for c in train_dataset.classes}\ntotal_n = sum(counts.values())\nweights = torch.tensor(\n    [np.power(total_n / counts[c], 0.5) for c in train_dataset.classes],\n    dtype=torch.float32\n).to(device)\n\nprint(\"Class weights:\")\nfor c, w in zip(train_dataset.classes, weights):\n    print(f\"  {c}: {w:.3f}\")\n\ncriterion = FocalLoss(alpha=weights, gamma=2.0).to(device)\n\noptimizer = torch.optim.AdamW([\n    {'params': model.encoder.spectral_mixer.parameters(), 'lr': 1e-4},\n    {'params': model.encoder.blocks[-2:].parameters(),    'lr': 5e-5},\n    {'params': model.encoder.norm.parameters(),           'lr': 5e-5},\n    {'params': model.head.parameters(),                   'lr': 1e-3},\n], weight_decay=0.05)\n\nscheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n\nprint(\"✓ Loss, optimizer, scheduler ready\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T16:52:11.109808Z","iopub.execute_input":"2026-02-13T16:52:11.110045Z","iopub.status.idle":"2026-02-13T16:52:11.136237Z","shell.execute_reply.started":"2026-02-13T16:52:11.110022Z","shell.execute_reply":"2026-02-13T16:52:11.135686Z"}},"outputs":[{"name":"stdout","text":"Class weights:\n  Aphid: 1.762\n  Blast: 3.464\n  RPH: 1.348\n  Rust: 4.743\n✓ Loss, optimizer, scheduler ready\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"# Decoder Head Training Loop","metadata":{}},{"cell_type":"code","source":"epochs           = 50\nbest_val_acc     = 0\npatience_counter = 0\npatience         = 7\n\nprint(f\"Starting fine-tuning for {epochs} epochs...\")\nprint(\"=\" * 70)\n\nfor ep in range(epochs):\n    # train\n    model.train()\n    tr_loss = tr_correct = tr_total = 0\n\n    for batch in tqdm(train_loader, desc=f\"Epoch {ep+1}/{epochs} [Train]\", leave=False):\n        x = batch['image'].to(device)\n        y = torch.argmax(batch['label'], dim=1).to(device)\n\n        optimizer.zero_grad()\n        logits = model(x)\n        loss   = criterion(logits, y)\n        loss.backward()\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n\n        tr_loss    += loss.item()\n        tr_correct += (logits.argmax(1) == y).sum().item()\n        tr_total   += y.size(0)\n\n    # validate\n    model.eval()\n    va_loss = va_correct = va_total = 0\n\n    with torch.no_grad():\n        for batch in tqdm(val_loader, desc=f\"Epoch {ep+1}/{epochs} [Val]\", leave=False):\n            x = batch['image'].to(device)\n            y = torch.argmax(batch['label'], dim=1).to(device)\n\n            logits   = model(x)\n            loss     = criterion(logits, y)\n\n            va_loss    += loss.item()\n            va_correct += (logits.argmax(1) == y).sum().item()\n            va_total   += y.size(0)\n\n    scheduler.step()\n\n    tr_acc = tr_correct / tr_total\n    va_acc = va_correct / va_total\n\n    print(f\"Epoch {ep+1}/{epochs} | \"\n          f\"Train Loss: {tr_loss/len(train_loader):.4f} | Train Acc: {tr_acc:.4f} | \"\n          f\"Val Loss: {va_loss/len(val_loader):.4f} | Val Acc: {va_acc:.4f}\")\n\n    if va_acc > best_val_acc:\n        best_val_acc = va_acc\n        torch.save(model.state_dict(), 'best_model.pth')\n        patience_counter = 0\n        print(f\"  ✓ New best! Saved.\")\n    else:\n        patience_counter += 1\n        print(f\"  No improvement ({patience_counter}/{patience})\")\n        if patience_counter >= patience:\n            print(f\"\\nEarly stopping at epoch {ep+1}\")\n            break\n\nprint(\"=\" * 70)\nprint(f\"✓ Fine-tuning complete! Best Val Acc: {best_val_acc:.4f}\")\nmodel.load_state_dict(torch.load('best_model.pth'))\nprint(\"✓ Best model loaded!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T16:52:11.137251Z","iopub.execute_input":"2026-02-13T16:52:11.137541Z","iopub.status.idle":"2026-02-13T17:27:22.084074Z","shell.execute_reply.started":"2026-02-13T16:52:11.137515Z","shell.execute_reply":"2026-02-13T17:27:22.083452Z"}},"outputs":[{"name":"stdout","text":"Starting fine-tuning for 50 epochs...\n======================================================================\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 1/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 1/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 1/50 | Train Loss: 3.0829 | Train Acc: 0.3737 | Val Loss: 3.6381 | Val Acc: 0.1778\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 2/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 2/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 2/50 | Train Loss: 2.4308 | Train Acc: 0.4343 | Val Loss: 2.1515 | Val Acc: 0.2500\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 3/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 3/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 3/50 | Train Loss: 2.1389 | Train Acc: 0.5088 | Val Loss: 2.0586 | Val Acc: 0.3000\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 4/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 4/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 4/50 | Train Loss: 1.8759 | Train Acc: 0.5303 | Val Loss: 2.2599 | Val Acc: 0.3278\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 5/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 5/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 5/50 | Train Loss: 1.7648 | Train Acc: 0.5732 | Val Loss: 1.9357 | Val Acc: 0.3778\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 6/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 6/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 6/50 | Train Loss: 1.6579 | Train Acc: 0.5922 | Val Loss: 1.7983 | Val Acc: 0.3667\n  No improvement (1/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 7/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 7/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 7/50 | Train Loss: 1.5715 | Train Acc: 0.6136 | Val Loss: 1.8477 | Val Acc: 0.3500\n  No improvement (2/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 8/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 8/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 8/50 | Train Loss: 1.5031 | Train Acc: 0.6332 | Val Loss: 1.9073 | Val Acc: 0.2944\n  No improvement (3/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 9/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 9/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 9/50 | Train Loss: 1.4376 | Train Acc: 0.6269 | Val Loss: 1.7616 | Val Acc: 0.3111\n  No improvement (4/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 10/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 10/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 10/50 | Train Loss: 1.4157 | Train Acc: 0.6383 | Val Loss: 1.8064 | Val Acc: 0.4444\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 11/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 11/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 11/50 | Train Loss: 1.3423 | Train Acc: 0.6427 | Val Loss: 1.7700 | Val Acc: 0.4389\n  No improvement (1/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 12/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 12/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 12/50 | Train Loss: 1.2902 | Train Acc: 0.6490 | Val Loss: 1.8380 | Val Acc: 0.4167\n  No improvement (2/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 13/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 13/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 13/50 | Train Loss: 1.2013 | Train Acc: 0.6654 | Val Loss: 1.8211 | Val Acc: 0.4556\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 14/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 14/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 14/50 | Train Loss: 1.2560 | Train Acc: 0.6850 | Val Loss: 1.6775 | Val Acc: 0.4444\n  No improvement (1/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 15/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 15/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 15/50 | Train Loss: 1.1642 | Train Acc: 0.6862 | Val Loss: 1.9336 | Val Acc: 0.4389\n  No improvement (2/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 16/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 16/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Epoch 16/50 | Train Loss: 1.0734 | Train Acc: 0.6982 | Val Loss: 1.6452 | Val Acc: 0.4944\n  ✓ New best! Saved.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 17/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 17/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"332c035791734957bd3c03bf1ed2b4c0"}},"metadata":{}},{"name":"stdout","text":"Epoch 17/50 | Train Loss: 1.1477 | Train Acc: 0.6894 | Val Loss: 1.8991 | Val Acc: 0.4167\n  No improvement (1/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 18/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9c44ebc9b594cbcbf527f2c4353d592"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 18/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"76caa62469644a45882d1db91304cbb4"}},"metadata":{}},{"name":"stdout","text":"Epoch 18/50 | Train Loss: 1.0187 | Train Acc: 0.7134 | Val Loss: 1.7876 | Val Acc: 0.3722\n  No improvement (2/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 19/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fdafdd456f024961b02e2756701fddf1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 19/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"afaa2ad2ad6f4bdf8812b74a39d07354"}},"metadata":{}},{"name":"stdout","text":"Epoch 19/50 | Train Loss: 1.0313 | Train Acc: 0.7039 | Val Loss: 1.7416 | Val Acc: 0.4722\n  No improvement (3/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 20/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43a986679e864c209715823c3ad27399"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 20/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bff67c3def843f8b83dbdb62ef326c7"}},"metadata":{}},{"name":"stdout","text":"Epoch 20/50 | Train Loss: 1.0734 | Train Acc: 0.7146 | Val Loss: 1.8467 | Val Acc: 0.4556\n  No improvement (4/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 21/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"830d56a407474d968d2fdaa74d51c248"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 21/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2a6774f4ae2451c91f1b1cbe1dc1b28"}},"metadata":{}},{"name":"stdout","text":"Epoch 21/50 | Train Loss: 0.9721 | Train Acc: 0.7134 | Val Loss: 1.7428 | Val Acc: 0.4556\n  No improvement (5/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 22/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc723c600594d44929975e3e9cffcbd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 22/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5af74a729a9d43d598dcb0ba4461c8d8"}},"metadata":{}},{"name":"stdout","text":"Epoch 22/50 | Train Loss: 1.0193 | Train Acc: 0.7367 | Val Loss: 1.6976 | Val Acc: 0.4722\n  No improvement (6/7)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Epoch 23/50 [Train]:   0%|          | 0/99 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f5cb8d2fb5fd471ba7fc5753b47ba497"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Epoch 23/50 [Val]:   0%|          | 0/6 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"672d080f25e142f394a55976aba5e218"}},"metadata":{}},{"name":"stdout","text":"Epoch 23/50 | Train Loss: 0.9641 | Train Acc: 0.7348 | Val Loss: 1.7694 | Val Acc: 0.4889\n  No improvement (7/7)\n\nEarly stopping at epoch 23\n======================================================================\n✓ Fine-tuning complete! Best Val Acc: 0.4944\n✓ Best model loaded!\n","output_type":"stream"}],"execution_count":16},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"eval_dataset = S2Disease(root_dir=DATA_ROOT, is_eval=True, target_size=(224, 224))\neval_loader  = DataLoader(eval_dataset, batch_size=32, shuffle=False, num_workers=0)\n\nprint(f\"Evaluation samples: {len(eval_dataset)}\")\n\nmodel.eval()\npredictions = []\nsample_ids  = []\n\nwith torch.no_grad():\n    for batch in tqdm(eval_loader, desc=\"Predicting\"):\n        x      = batch['image'].to(device)\n        # normalize eval images\n        mean   = x.mean(dim=(2, 3), keepdim=True)\n        std    = x.std(dim=(2, 3), keepdim=True) + 1e-6\n        x      = (x - mean) / std\n        logits = model(x)\n        preds  = logits.argmax(dim=1)\n        predictions.extend(preds.cpu().numpy())\n        sample_ids.extend(batch['sample_id'])\n\nprint(f\"✓ Generated {len(predictions)} predictions\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T17:34:06.342575Z","iopub.execute_input":"2026-02-13T17:34:06.342855Z","iopub.status.idle":"2026-02-13T17:34:08.076527Z","shell.execute_reply.started":"2026-02-13T17:34:06.342830Z","shell.execute_reply":"2026-02-13T17:34:08.075660Z"}},"outputs":[{"name":"stdout","text":"Evaluation samples: 40\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Predicting:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b276f9e6fa4546038ab424d0e5daaeed"}},"metadata":{}},{"name":"stdout","text":"✓ Generated 40 predictions\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"submission = pd.DataFrame({\n    'sample_id':  sample_ids,\n    'prediction': [train_dataset.idx_to_class[p] for p in predictions]\n})\n\nprint(\"\\nPrediction distribution:\")\nprint(submission['prediction'].value_counts())\n\nsubmission.to_csv('/kaggle/working/submission.csv', index=False)\nprint(\"\\n✓ Saved to submission.csv\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T17:36:04.796755Z","iopub.execute_input":"2026-02-13T17:36:04.797500Z","iopub.status.idle":"2026-02-13T17:36:04.805541Z","shell.execute_reply.started":"2026-02-13T17:36:04.797467Z","shell.execute_reply":"2026-02-13T17:36:04.804854Z"}},"outputs":[{"name":"stdout","text":"\nPrediction distribution:\nprediction\nRPH      14\nAphid    12\nRust      8\nBlast     6\nName: count, dtype: int64\n\n✓ Saved to submission.csv\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-13T17:34:16.154684Z","iopub.execute_input":"2026-02-13T17:34:16.155307Z","iopub.status.idle":"2026-02-13T17:34:16.163834Z","shell.execute_reply.started":"2026-02-13T17:34:16.155278Z","shell.execute_reply":"2026-02-13T17:34:16.163283Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"                           sample_id prediction\n0   994b5409c8e946538d87109a99897659        RPH\n1   1a419acc1ecc467897d5477a47353fa8        RPH\n2   8662df21b2c94788adce4a885ae2b4dc      Blast\n3   a564868c3d8c4d4fabde67a536f178ad       Rust\n4   796e611aaf8a4f0db57cb79be058f3ae       Rust\n5   e77d3a0965fe46d9b3275a7d7f34dbe2        RPH\n6   a39dcd0a21824289bb38b40ddf98da89      Aphid\n7   e427f07618794fd58dfc9e6c786e3743       Rust\n8   13739e32e7a84f669e6ef1284715e93b        RPH\n9   b6eeb2bfd281476883fc273b61133e60        RPH\n10  c283cbe9d0ae46aaa9adf354b714f68f      Aphid\n11  2fb5f497ae1b4b1eb7e8d7ced143aa46        RPH\n12  8a9d2c25f8f44309ac7d2318ba5f2d1d        RPH\n13  fe481b0935fd4043b964c287a76321c2      Blast\n14  5bf370118f3043f1bbeafbb91bd78f32        RPH\n15  e66d89ba472d42cf91508a2182553b60        RPH\n16  e3a69009935d4e93b93a72554fb8a51e       Rust\n17  4da1b698cdad4c8db6c1716a51a56bd4      Aphid\n18  05835a9764364429b5ac3e11b052649d      Aphid\n19  7f4ecf086b6b4c04ae36a0d24b27063a      Aphid\n20  7ba3e7677fd34c738b687571c7a90ad0      Aphid\n21  dd2ebc9b0ac54d5f805920b08f289f04        RPH\n22  342a74c6432d458d956ba20ad71339c0       Rust\n23  e0e8b341a8da414e854c4062eb8b8ea5        RPH\n24  abf0eb65010948d483779cb06b2902c5        RPH\n25  b6d4ca93bff44b9fa54abe80917e75dc        RPH\n26  98ceba6c29ab465d94137a6dfbbeb273      Blast\n27  c36f29bc6d8d4c1db0334f8400d2f63e       Rust\n28  827d1559e90d47438052fd39e1b8e919      Aphid\n29  34ff69d337a448d5acf24c06d134c07a       Rust\n30  b713133f03304247b6e8f28f7ddf43a8      Blast\n31  740056f890bf4763843499153cf3a020      Aphid\n32  d07471b19c5548f8bbd790d7748f6080      Blast\n33  36eb3780202748baa0164000b4e2e5b3      Aphid\n34  97e5857a759544578b5234a80da85223      Blast\n35  310283f25b5f4b038114acbb6d61a357      Aphid\n36  fc6f63642553437794b2a33f4ce73430        RPH\n37  b00be67eaf0640f797c964a797366a87       Rust\n38  67c260bfd836456195f80e584c614e83      Aphid\n39  7f1097e839d4450091a631943803a149      Aphid","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sample_id</th>\n      <th>prediction</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>994b5409c8e946538d87109a99897659</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1a419acc1ecc467897d5477a47353fa8</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8662df21b2c94788adce4a885ae2b4dc</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a564868c3d8c4d4fabde67a536f178ad</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>796e611aaf8a4f0db57cb79be058f3ae</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>e77d3a0965fe46d9b3275a7d7f34dbe2</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>a39dcd0a21824289bb38b40ddf98da89</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>e427f07618794fd58dfc9e6c786e3743</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>13739e32e7a84f669e6ef1284715e93b</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>b6eeb2bfd281476883fc273b61133e60</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>c283cbe9d0ae46aaa9adf354b714f68f</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>2fb5f497ae1b4b1eb7e8d7ced143aa46</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>8a9d2c25f8f44309ac7d2318ba5f2d1d</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>fe481b0935fd4043b964c287a76321c2</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>5bf370118f3043f1bbeafbb91bd78f32</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>e66d89ba472d42cf91508a2182553b60</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>e3a69009935d4e93b93a72554fb8a51e</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>4da1b698cdad4c8db6c1716a51a56bd4</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>05835a9764364429b5ac3e11b052649d</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>7f4ecf086b6b4c04ae36a0d24b27063a</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>7ba3e7677fd34c738b687571c7a90ad0</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>dd2ebc9b0ac54d5f805920b08f289f04</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>342a74c6432d458d956ba20ad71339c0</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>e0e8b341a8da414e854c4062eb8b8ea5</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>abf0eb65010948d483779cb06b2902c5</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>b6d4ca93bff44b9fa54abe80917e75dc</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>98ceba6c29ab465d94137a6dfbbeb273</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>c36f29bc6d8d4c1db0334f8400d2f63e</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>827d1559e90d47438052fd39e1b8e919</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>34ff69d337a448d5acf24c06d134c07a</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>b713133f03304247b6e8f28f7ddf43a8</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>740056f890bf4763843499153cf3a020</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>d07471b19c5548f8bbd790d7748f6080</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>36eb3780202748baa0164000b4e2e5b3</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>97e5857a759544578b5234a80da85223</td>\n      <td>Blast</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>310283f25b5f4b038114acbb6d61a357</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>fc6f63642553437794b2a33f4ce73430</td>\n      <td>RPH</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>b00be67eaf0640f797c964a797366a87</td>\n      <td>Rust</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>67c260bfd836456195f80e584c614e83</td>\n      <td>Aphid</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>7f1097e839d4450091a631943803a149</td>\n      <td>Aphid</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}